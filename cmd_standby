#!/usr/bin/python
#
#
# cmd_standby copyright command prompt inc
#
#
# $Id$
"""
License

Copyright Command Prompt, Inc.

Permission to use, copy, modify, and distribute this software and its
documentation for any purpose, without fee, and without a written agreement
is hereby granted, provided that the above copyright notice and this
paragraph and the following two paragraphs appear in all copies.

IN NO EVENT SHALL COMMAND PROMPT, INC BE LIABLE TO ANY PARTY FOR
DIRECT, INDIRECT, SPECIAL, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, INCLUDING
LOST PROFITS, ARISING OUT OF THE USE OF THIS SOFTWARE AND ITS DOCUMENTATION,
EVEN IF COMMAND PROMPT, INC HAS BEEN ADVISED OF THE POSSIBILITY OF
SUCH DAMAGE.

COMMAND PROMPT, INC SPECIFICALLY DISCLAIMS ANY WARRANTIES,
INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS FOR A PARTICULAR PURPOSE. THE SOFTWARE PROVIDED HEREUNDER IS ON AN
"AS IS" BASIS, AND COMMAND PROMPT, INC HAS NO OBLIGATIONS TO
PROVIDE MAINTENANCE, SUPPORT, UPDATES, ENHANCEMENTS, OR MODIFICATIONS.
"""

import os
import shutil
import sys
import re

from sys import *
from os import system
from cmd_worker import CMDWorker


argslist = (("-A", "--action", dict(dest="pgctl_action", action="store", help="Start/Stop PostgreSQL", metavar="start|stop|stop_basebackup")),
            ("-B", "--basebackup", dict(dest="base_backup", action="store_true", help="Start a base backup", metavar="FILE")),
            ("-C", "--config", dict(dest="configfilename", action="store", help="Name of the archiver config file", metavar="FILE", default='cmd_standby.ini')),
            ("-F", "--failover", dict(dest="failover", action="store", help="Value is arbitrary 3 digit number. It is simply a safeguard measure and you could use -F999 or -F372 etc.", metavar="VALUE")),
            ("-I", "--dbinit", dict(dest="dbinit", action="store_true", help="Use before -B", metavar="FILE")),
            ("-P", "--ping", dict(dest="ping_check", action="store_true", help="Is my master alive?", metavar="FILE")),
            ("-R", "--recovertotime", dict(dest="recovertotime", action="store", help="To restore to a specific point in time", metavar="TIMESTAMP")),
            ("-S", "--standby", dict(dest="standby", action="store_true", help="Enter standby mode", metavar="FILE")))

classdict = (('pgversion', 's', None),
           ('ssh', 's', None),
           ('rsync', 's', None),
           ('rsync_flags', 's', ""),
           ('pg_ctl', 's', None),
           ('r_psql', 's', None),
           ('pg_standby', 's', None),
           ('master_public_ip', 's', None),
           ('master_local_ip', 's', ""),
           ('user', 's', None),
           ('debug', 'b', False),
           ('ssh_debug', 'b', False),
           ('port', 'i', None),
           ('ssh_timeout', 'i', None),
           ('archivedir', 's', None),
           ('pgdata', 's', None),
           ('postgresql_conf', 's', None),
           ('pg_hba_conf', 's', None),
           ('no_copy_conf', 'b', False),
           ('recovery_conf', 's', ""),
           ('logfile', 's', ""),
           ('action_failover', 's', None),
           ('numarchives', 'i', None),
           ('use_streaming_replication', 'b', False),
           ('trigger_file', 's', ""),
           ('repl_db_user', 's', 'postgres'),
           ('repl_db_password', 's', ""),
           ('sslmode', 's', 'prefer'),
           ('notify_ok', 's', None),
           ('notify_warning', 's', None),
           ('notify_critical', 's', None))


class RsyncFailure(Exception):
    """ Class to propagate rsync exceptions"""
    pass

class SSHFailure(Exception):
    """ Class to propagate SSH errors, i.e. wrong password """
    pass

class RemoteNoData(Exception):
    """ Class to propagate errors when remote host returns empty data """
    pass


class CMDStandby(CMDWorker):

    # Validate the command line
    # XXX: replace those parser.error with exceptions in the future
    # for now, they seem to be fine, cause they only happen in the very
    # beginning, when to resources are allocated yet.
    @staticmethod
    def command_line_check_func(parser, options):
        if options.configfilename == None:
            parser.error("option -C is required")

        if options.recovertotime and not (options.failover == '999'):
            parser.error("option -R requires open -F999")

        if options.pgctl_action:
            valid_action = ['start', 'stop', 'stop_basebackup', 'start_basebackup']
            if options.pgctl_action not in valid_action:
                parser.error("option -A requires one of start, stop, stop_basebackup or start_basebackup")

    # Let's make sure executables can be reached
    def check_config_func(self, options):
        pathvars = [self.ssh, self.rsync, self.pg_ctl, self.postgresql_conf, self.pg_hba_conf]
        if not self.use_streaming_replication:
            pathvars.extend([self.pg_standby, self.archivedir])
        elif options.recovertotime:
            raise Exception('CONFIG: Unable to use recovery_target_time with streaming replication')
        for element in pathvars:
            try:
                if element != self.archivedir:
                    os.stat("%s" % (str(element)))
                else:
                    # make a new directory if archivedir doesn't exist.
                    if not os.access(element, os.R_OK|os.W_OK|os.X_OK):
                        os.mkdir(element, 0700)
            except OSError, e:
                raise Exception("CONFIG: can't stat %s %s" % (str(element), str(e)))

    #
    # Create pg_xlog dir if missing, follow symlink if present
    #
    def check_pgxlog_path_func(self):
        pg_xlog_dir = "%s/%s" % (str(self.pgdata), str('pg_xlog'))
        pg_xlog_realpath = os.path.realpath(pg_xlog_dir)
        success = True
        try:
            # XXX: we might be able to stat the directory, but still get the
            # undersired permissions (i.e no write access).
            os.stat(pg_xlog_realpath)
        except:
            try:
                if self.debug:
                    print "creating pg_xlog directory: %s" % (pg_xlog_realpath)
                os.makedirs(pg_xlog_realpath, 0700)
            except OSError, e:
                print "ERROR: %s" % (str(e))
                print "HINT: You may have permission problems"
                print "Make sure that %s has the ability to create the directory %s" % ((str(self.user), (str(pg_xlog_realpath))))
                success = False
            except:
                success = False
        return success

    def set_rsync_options(self):
        self.rsync_flags = "-al %s --delete " % (self.rsync_flags)
        if self.debug:
            self.rsync_flags += '-v --stats '

    def set_pg_standby_options(self):
        self.pg_standby_flags = '-s5 -w0 -c '
        if self.debug:
            self.pg_standby_flags += '-d '

        if self.pgversion == '8.2':
            self.pg_standby_args = "%%f %%p -k%s " % (self.numarchives)
        else:
            self.pg_standby_args = "%f %p %r "

    def set_connect_and_copy_options(self):
        # Yes the odd counted " is needed because of the way we have to quote within the command
        # There may be a better way to do this, but I got tired of fighting.
        ssh_connect = """%s %s %s@%s """ % (self.ssh, self.ssh_flags, self.user, self.master_public_ip)
        psql_connect = """ "%s -A -t -U%s -p%s -dpostgres """ % (self.r_psql, self.user, self.port)

        if self.master_local_ip:
            psql_connect += '-h%s ' % (self.master_local_ip,)

        self.copy_dirs = "%s %s --exclude=pg_log/ --exclude=pg_xlog/ --exclude=postgresql.conf --exclude=pg_hba.conf --exclude=postmaster.pid -e ssh %s@%s:" % (self.rsync, self.rsync_flags, self.user, self.master_public_ip)
        self.ssh_psql = ssh_connect + psql_connect

        self.pgctl_base = "%s -D %s " % (self.pg_ctl, self.pgdata)
        if self.no_copy_conf:
            self.pgctl_base += "-o \"-c config_file=%s\" " % (self.postgresql_conf,)
        if self.logfile:
            self.pgctl_base += "-l \"%s\" " % (self.logfile,)

    def set_recovery_options(self, options):
        # set more sane value for trigger and recovery files now that we know
        # pgdata value:
        if self.trigger_file == "":
            self.trigger_file = "%s/cmd_end_recovery" % (self.pgdata,)
        if self.recovery_conf == "":
            self.recovery_conf = """%s/recovery.conf""" % (self.pgdata,)
        # Recovery string for recovery.conf
        self.recovery_stopped_file = re.sub(r'recovery.conf$', 'recovery.stopped', self.recovery_conf)
        if not self.use_streaming_replication or (options.failover == '999'):
            self.recovery_string = "restore_command = "
            if options.failover == '999':
                self.recovery_string += """'cp %s/%%f "%%p"' """ % (self.archivedir,)
                if options.recovertotime:
                    self.recovery_string += """\nrecovery_target_time = '%s' """ % (options.recovertotime,)
            else:
                self.recovery_string += """'%s %s %s %s' """ % (self.pg_standby, self.pg_standby_flags, self.archivedir, self.pg_standby_args)
        else:
            # streaming replication and not failover, if password is not supplied
            # it's expected to be found in .pgpass or via PGPASSWORD variable.
            # see http://www.postgresql.org/docs/current/static/libpq-envars.html
            primary_conninfo_string = "host=%s port=%s user=%s sslmode=%s " % (self.master_public_ip, self.port, self.repl_db_user, self.sslmode)
            if len(self.repl_db_password) > 0:
                primary_conninfo_string += "password=%s " % (self.repl_db_password,)
            self.recovery_string = """standby_mode = 'on'\nprimary_conninfo = '%s' \ntrigger_file = '%s' """ % (primary_conninfo_string, self.trigger_file)

    def set_options(self, options):
        """ Wrapper for varions set_ functions """
        self.set_ssh_flags()
        self.set_rsync_options()
        self.set_pg_standby_options()
        self.set_connect_and_copy_options()
        self.set_recovery_options(options)

    # Check the master for being alive
    def ping_check_func(self):
        success = self.exec_query_on_primary("""'SELECT 1'""")
        for row in success:
            row = row.rstrip('\n')
            if self.debug:
                print "DEBUG: " + row
            if str(row) != "1":
                self.notify_external(critical=True, message="no response from master")
                return False
            else:
                return True

    # TODO: replace popen with subprocess module calls.
    def exec_query_on_primary(self, query, emptyok=True):
        """ Runs a database query on the primary node and returns the psql output"""
        if self.debug:
            print 'DEBUG: executing query %s by %s' % (self.ssh_psql, query)
        p = os.popen("%s -c %s\"" % (self.ssh_psql, query))
        result = p.readlines()
        exitstatus = p.close()
        # check whether ssh has terminated due to an error occurred, likely an incorrect password
        if exitstatus == 255:
            raise SSHFailure
        if len(result) == 0 and not emptyok:
            raise RemoteNoData(query)
        return result

    # This function gives us all the non pgdata directories required
    # for operation, such as table spaces
    def primary_get_tablespace_paths(self):
        try:
            paths = self.exec_query_on_primary("""'SELECT * FROM cmd_get_data_dirs()'""")
        except:
            print "ERROR: Unable to get namespace paths"
            print "HINT: Did you apply cmd_standby.sql?"
            raise 
        return paths

    def primary_get_datadir_path(self):
        try:
            path = self.exec_query_on_primary("""'SELECT * FROM cmd_get_pgdata() LIMIT 1'""", False)
        except RemoteNoData:
            print "ERROR: Unable to get namespace paths"
            print "HINT: Did you apply cmd_standby.sql?"
            raise
        return path[0]

    # Start a base backup on the master
    # First we issue a checkpoint and then a start backup
    def start_backup_func(self):
        retval = os.system("rm -rf %s/*" % (self.archivedir,))
        if retval:
            raise Exception("Unable to remove old archives")
        success = self.exec_query_on_primary(""" 'checkpoint' """)
        for row in success:
            row = row.rstrip('\n')
            if self.debug:
                print "DEBUG: " + row
            if str(row) != "CHECKPOINT":
                print "ERROR: Unable to execute CHECKPOINT"
                self.notify_external(critical=True, message="Unable to execute CHECKPOINT")
                return False
        success = self.exec_query_on_primary(""" 'SELECT cmd_pg_start_backup()' """)
        for row in success:
            row = row.rstrip('\n')
            if self.debug:
                print "DEBUG: cmd_pg_start_backup:  " + row
            if str(row) != "1":
                print "ERROR: Unable to start base backup"
                return False
        return True

    def stop_backup_func(self):
        success = self.exec_query_on_primary(""" 'SELECT cmd_pg_stop_backup()' """)
        for row in success:
            row = row.rstrip('\n')
            if self.debug:
                print "DEBUG: cmd_pg_stop_backup: " + row
            if str(row) != "1":
                print "ERROR: Unable to stop base backup"
                return False
        return True

    # Simple function to help ensure we have all paths created for postgresql
    def dbinit_func(self):
        # check whether pgdata and tablespace paths exist, create if not.
        paths = self.primary_get_tablespace_paths()
        paths.insert(0, self.pgdata)
        for row in paths:
            if self.debug:
                print "DEBUG: " + row
            row = row.rstrip('\n')
            if not os.path.isdir(row):
                os.makedirs(row, 0700)

    # Takes a base backup of master. This function is tricky because
    # there is a possibility of a non 0 exit status even when successful
    def base_backup_func(self):
        # first, copy tablespaces
        paths = self.primary_get_tablespace_paths()
        for row in paths:
            if self.debug:
                print "DEBUG: " + row
            row = row.rstrip('\n')
            retval = system("%s%s/ %s/" % (self.copy_dirs, row, row))
            if retval:
                raise RsyncFailure
        # finally, copy over pgdata
        master_pgdata = self.primary_get_datadir_path().strip('\n')
        # Before, doing the rsync, make sure we cleanup pg_xlog for streaming replication
        # XXX: does it makes sense at all, given that we don't copy pg_xlog from master?
        if self.use_streaming_replication:
            if self.debug:
                print "DEBUG: cleaning up " + master_pgdata + "/pg_xlog/ directory before rsync"
            os.system("rm -rf " + self.pgdata + "/pg_xlog/*")
        retval = system("%s%s/ %s/" % (self.copy_dirs, master_pgdata, self.pgdata))
        if retval:
            raise RsyncFailure

    # Start postgresql
    def start_postgresql_func(self):
        retval = system(self.pgctl_base + " start")
        if retval:
            print "Unable to start PostgreSQL"
            self.notify_external(warning=True, message="Unable to start PostgreSQL")
            exit(1)

    # Stop postgresql
    def stop_postgresql_func(self):
        retval = system(self.pgctl_base + " -m fast stop")
        if retval:
            print "Unable to stop PostgreSQL"
            self.notify_external(critical=True, message="Unable to stop PostgreSQL")
            exit(1)

    # Writes recovery.conf file to pgdata
    def write_recovery_func(self):
        try:
            file = open(self.recovery_conf, 'w')
            file.write('%s' % (self.recovery_string))
            file.close()
        except Exception, e:
            print "Unable to write recovery file: %s" % (self.recovery_conf)
            print "Exception: %s" % (str(e))
            self.notify_external(critical=True, message="Unable to write recovery file: %s" % (e,))
            exit(1)

    # Copies in production slave configurations from storage location to production pgdata location
    def copy_confs_func(self):
        if self.no_copy_conf:
            return
        for f in (self.postgresql_conf, self.pg_hba_conf):
            try:
                shutil.copy(f, self.pgdata)
            except Exception, e:
                print "Unable to copy configuration files: %s" % (f)
                print "Exception: %s" % (str(e))
                exit(1)

    # Standby function, we need to write the recovery configuration
    # and start postgresql
    def standby_func(self):
        self.write_recovery_func()
        self.start_postgresql_func()

    # Function allows you to specify a script to execute on failover
    # The script must return 0 to be considered successful
    def failover_action_func(self):
        if self.action_failover:
            retval = system("%s" % (self.action_failover))
            if retval:
                self.notify_external(critical=True, message="failover action returned non-zero exit code")
                exit(1)
            else:
                print "NOTICE: Statistics are not replicated in warm standy mode."
                print "HINT: Execute ANALYZE on your databases"
                exit(0)

    def run_base_backup(self):
        result = True
        check = self.check_pgpid_func()
        if check == 0:
            print "ERROR: Can not take base backup with PG running locally"
            result = False
        else:
            if self.start_backup_func():
                try:
                    self.base_backup_func()
                except RsyncFailure:
                    print
                    print "WARNING: Failed to get 0 exit status"
                    print "LOG: Check your rsync errors as this may be harmless"
                    print "LOG: File vanished: .... is ok"
                    print "NOTICE: You will need to issue a -Astop_basebackup if you deem these errors harmless"
                    print
                    result = False
                except Exception, e:
                    print "ERROR: %s" % (str(e),)
                    result = False
                else:
                    success = self.check_pgxlog_path_func()
                    if not success:
                        self.notify_external(critical=True, message="unable to access xlog path")
                        result = False
                finally:
                    self.stop_backup_func()
        return result

    def do_failover(self, options):
        check = self.check_pgpid_func()
        if check == 0:
            self.stop_postgresql_func()
        # Note: we already check that use_streaming_replication is not issued
        # with recovertotime inside check_config_func.
        if self.use_streaming_replication:
            if check == 0:
                # pgsql was running, just touch the trigger file and all should be good.
                try:
                    file = open(self.trigger_file, "w")
                    file.close()
                except Exception, e:
                    print "Unable to write trigger file: %s" % (self.trigger_file,)
                    print "Exception: %s" % (str(e))
                    return False
            else:
                # pgsql is NOT running, and we are trying to failover.  Lets try to rename recovery.conf into recovery.stopped and try to start pgsql.
                os.rename(self.recovery_conf, self.recovery_stopped_file)
        else:
            self.write_recovery_func()
        self.copy_confs_func()
        self.start_postgresql_func()
        self.failover_action_func()
        self.notify_external(ok=True, mesage="successfull failover")
        return True

if __name__ == '__main__':
    # before we do anything, let's just check you we are
    if os.geteuid() == 0:
        sys.exit("\nBad Mojo... no root access for this script\n")

    standby = CMDStandby(classdict)
    (options, args) = standby.parse_commandline_arguments(argslist, CMDStandby.command_line_check_func)

    configfilename = options.configfilename
    base_backup = options.base_backup
    setstandby = options.standby
    dbinit = options.dbinit
    pgctl_action = options.pgctl_action
    ping_check = options.ping_check
    failover = options.failover
    recovertotime = options.recovertotime

    try:
        cfg_vals = standby.load_configuration_file(configfilename)
    except Exception, e:
        print "ERROR: %s" % (e,)
        exit(2)

    # Before we do anything, let's check the configuration
    standby.check_config_func(options)

    # Configure ssh command-line string, rsync options,
    # pg_standy arguments and recovery options.
    standby.set_options(options)
    # perform different actions depending on command-line switches
    if dbinit:
        check = standby.check_pgpid_func()
        if check == 0:
            print "ERROR: Can not execute --dbinit with PG running locally"
            exit(1)
        else:
            try:
                standby.dbinit_func()
            except OSError, e:
                print "ERROR: %s" % (str(e))
                print "HINT: You may have permission problems"
                print "Make sure that %s has the ability to create the directory: " % (self.user, self.pgdata)
                exit(1)
    try:
        # Run a base backup
        if base_backup:
            success = standby.run_base_backup()
            if not success:
                exit(1)
            else:
                exit(0)

        # If we want to failover to the latest good transaction
        if options.failover == '999':
            sucess = standby.do_failover(options)
            if not sucess:
                exit(1)
            else:
                exit(0)

        # If we want to enter standby mode
        if setstandby:
            check = standby.check_pgpid_func()
            if check == 0:
                print "ERROR: Can not enter standby mode if PG is already running"
                exit(1)
            else:
                standby.standby_func()

        # If we want to check if we can talk to the master
        if ping_check:
            got_response = standby.ping_check_func()
            if got_response:
                print "SUCCESS: got response from master"
                exit(0)
            else:
                print "ERROR: got no response from master"
                exit(1)
    except RemoteNoData, e:
        print "ERROR: remote host returned no data for query %s", (e,)
        exit(1)
    except SSHFailure:
        print "Received error code 255 from ssh, likely due to the wrong password"
        exit(1)

    # If we want to start or stop postgresql on the slave
    if pgctl_action == 'start':
        standby.start_postgresql_func()
    elif pgctl_action == 'stop':
        standby.stop_postgresql_func()
    if pgctl_action == 'stop_basebackup':
        standby.stop_backup_func()
